[
    {
        "title": "Python中文网 官网",
        "content": "注意: 虽然JavaScript对于本网站不是必需的，但您与内容的互动将受到限制。请打开 JavaScript 以获得完整的体验.  可扩展编程的核心是定义函数。Python 允许强制和可选参数、关键字参数，甚至是任意参数列表. 有关在 Python 3 中定义函数的更多信息 列表（在其他语言中称为数组）是 Python 可以理解的复合数据类型之一。可以使用其他内置函数对列表进行索引、切片和操作. 更多关于 Python 3 中的列表 使用 Python 进行计算很简单，表达式语法也很简单：运算符+, -, * 和 / 按预期工作; 括号 () 可用于分组. 有关 Python 3 中简单数学函数的更多信息. Python 知道其他语言常用的控制流语句 — if, for, while 和 range — 当然，有一些自己的曲折. Python 3 中的更多控制流工具 任何其他语言的有经验的程序员都可以很快学会 Python，初学者发现简洁的语法和缩进结构很容易学习. 通过我们的 Python 3 概述来满足您的胃口 . Python是一种编程语言，可以让你快速工作 并更有效地集成系统. 了解更多 无论您是编程新手还是经验丰富的开发人员，都可以轻松学习和使用 Python. 从我们的初学者指南开始 Python 源代码和安装程序可供所有版本下载! 最新: Python 3.12.3 Python 标准库的文档以及教程和指南可在线获取. docs.python.org  \n    寻找工作或有与 Python 相关的职位，您想招聘？我们重新启动的社区运营的工作委员会是您要去的地方.\n jobs.python.org 更多 更多 更多 使用Python脚本分析SEO和您网站上的断开链接 作者: Marnix de Munck 更多 \n    Python 软件基金会的使命是促进、保护和推进 Python 编程语言，并支持和促进多元化和国际化的Python程序员社区的发展. 了解更多\n \n成为会员\n捐赠给 PSF\n \nCopyright ©2001-2024.\n                             Python 软件基金会\n                             法律声明\n                             隐私政策 \n                             Python中文网\n",
        "URL": "http://www.baidu.com/link?url=XYS2UZDHtTqrYnR62LUlqKCLW9Zcqa1bDlFBYyVdZLFxgR77Cqix5DaxBj8MSOmS",
        "score": 62.44
    },
    {
        "title": "python是什么意思_python的翻译_音标_读音_用法_例句_爱...",
        "content": "大小写变形:Python Embroiders uses the and beautiful woolen embroidery exactly , sets up the python water curved. 绣活多采用俊雅清丽的绒绣, 弯立蟒水. 期刊摘选 Serpent blood spurted through the air, and in a minute, the huge python was dead. 蛇血在空中喷射出来, 很快, 大蟒蛇就死了. 期刊摘选 In such cases, Python may be just the language for you. 遇到以上情况, Python可能 就是你要找的语言. 期刊摘选 A giant python sure gave these folks a scare. 这条巨蟒足以让村民大吃一惊. 期刊摘选 I know. I accidentally set a python on my cousin Dudley at the zoo once. 我知道了, 我是说,上次我曾无意中和我表哥达德利在动物园的时候放走了一条大蟒. 期刊摘选 The southern African python occurs in open savannah, riverine scrub and rocky areas. 辽阔的非洲稀树草原, 溪流边的灌木丛中,以及多岩石地带,都是南非蟒经常出没的地方. 期刊摘选 Jones I think we've all relaxed a bit about Python. Jones:我想我们关于Python这个 话题都已经放得开了. 期刊摘选 Programmers can compile the Python source code to java byte code, running it on JVM ( Java Virtual Machine ). 程序员可以把Python源代码编译成Java的字节码, 并在Java虚拟机上运行此代码. 期刊摘选 Jython is an open source implementation of Python combining with Java platform. Jython是Python编程语言结合Java平台的一种开源执行. 期刊摘选 Making references to Monty Python skits in documentation is not only allowed, it is encouraged! 在文档中引用MontyPython典故不仅是允许的, 而且还受到鼓励! 期刊摘选 I don't know either Perl or Python. Which should I learn? 我即不懂Perl也不动Python.我应该学习 什么 ? 期刊摘选 Traces the python, has ease of mind, guarantees you bon voyage. 摸摸巨蟒, 心情舒畅, 保您一路平安. 期刊摘选 Another idea is to require python owners to have their pets fitted with microchips. 另一个想法是让养蛇人给他们的宠物配上微芯片. 期刊摘选 Incidentally, knowledge about this subject is useful for any advanced Python programmer. 另外, 这一切的知识对于任何高级Python程序员都非常有用. 期刊摘选 Fortunately, Python offers enough power to make it pretty trivial to satisfy this requirement. 在那样情况下, 你的最初翻译的数据结构接近于你正在翻译的代码是更可取的. 期刊摘选 Highly portable SQL query engine based in Python with transactions, recovery and client server mode. 非常方便的基于事务处理的sql查询引擎, 恢复和客户服务模式. 期刊摘选 A scope is a textual region of a Python program where a namespace is directly accessible. 作用域是指Python程序可以直接访问到的命名空间. 期刊摘选 Or, you can type python zpasspwd. py inituser and follow the prompts. 或者你可以输入pythonzpasspwd. py初始化用户并且跟着提示做. 期刊摘选 After a few episodes, a small but enthusiastic Python fan base started to develop. 播出了几集之后, 一个规模小但是很狂热的爱好者基础群体建立起来了. 期刊摘选 Jython is not fully compatible with the standard Python language. Jython与标准Python语言并非完全兼容. 期刊摘选 In Python, assignment is not an expression. 在python中, 赋值不是一个表达式. 期刊摘选 This reference manual describes the Python programming language. It is not intended as a tutorial. 本参考手册描述了Python程序设计语言但本文档并不是新手手册. 期刊摘选 In the last several years, the popularity of ball pythons ( Python regius ) has skyrocketed. 在过去若干年里, 球 蟒 的普及如烟花般绚烂. 期刊摘选 A person, python, snake battle about to begin. 一场人 、 蟒 、 蛇的激战即将开始. 期刊摘选 In this paper, a simple butpracticable AOP utility will be designed and implemented with Python. 本文将尝试基于Python语言 环境, 利用其“动态语言”特性与的“面向对象模型”,设计实现一个轻量工具. 期刊摘选 Custom Text supports Python code: The Custom Text Editor now supports Python code. 自定义字符支持Python代码: 自定义字符编辑器现在支持Python代码. 期刊摘选 Question 2 : yeah, that sounds horrible to keep a python as pet. Right? 问题 2: 是的, 把蟒蛇当宠物养, 听起来很恐怖,是把? 期刊摘选 He opened up a cage and lifted out a 6ft python. 他打开笼子，拎出一条6英尺长的蟒蛇。 柯林斯例句",
        "URL": "http://www.baidu.com/link?url=vn5tfJ-XrhWk0ktqLsUeye0gY7E2DLUzxi6al7K1NRHfOS8_CZFs1YTatYq2JEdw",
        "score": 59.94
    },
    {
        "title": "Welcome to Python.org 官方",
        "content": "Notice: While JavaScript is not essential for this website, your interaction with the content will be limited. Please turn JavaScript on for the full experience.  The core of extensible programming is defining functions. Python allows mandatory and optional arguments, keyword arguments, and even arbitrary argument lists. More about defining functions in Python 3 Lists (known as arrays in other languages) are one of the compound data types that Python understands. Lists can be indexed, sliced and manipulated with other built-in functions. More about lists in Python 3 Calculations are simple with Python, and expression syntax is straightforward: the operators +, -, * and / work as expected; parentheses () can be used for grouping. More about simple math functions in Python 3. Python knows the usual control flow statements that other languages speak — if, for, while and range — with some of its own twists, of course. More control flow tools in Python 3 Experienced programmers in any other language can pick up Python very quickly, and beginners find the clean syntax and indentation structure easy to learn. Whet your appetite with our Python 3 overview. Python is a programming language that lets you work quickly and integrate systems more effectively. Learn More Whether you're new to programming or an experienced developer, it's easy to learn and use Python. Start with our Beginner’s Guide Python source code and installers are available for download for all versions! Latest: Python 3.12.6 Documentation for Python's standard library, along with tutorials and guides, are available online. docs.python.org Looking for work or have a Python related position that you're trying to hire for? Our relaunched community-run job board is the place to go. jobs.python.org More More More Using Python with Gretel.ai to Generate Synthetic Location Data by Alex Watson, co-founder and CPO, Gretel.ai More The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers. Learn more  \nBecome a Member\nDonate to the PSF\n \nCopyright ©2001-2024.\n                             Python Software Foundation\n                             Legal Statements\n                             Privacy Policy\n\n",
        "URL": "http://www.baidu.com/link?url=XYS2UZDHtTqrYnR62LUlqL1mj_gok8iZSngWDtnqNdUNwNlTwAIFBYhcv4GlVK7a",
        "score": 58.25
    },
    {
        "title": "Python 爬虫介绍|",
        "content": "爬虫：一段自动抓取互联网信息的程序，从互联网上抓取对于我们有价值的信息。 Python 爬虫架构主要由五个部分组成，分别是调度器、URL管理器、网页下载器、网页解析器、应用程序（爬取的有价值数据）。 下面用一个图来解释一下调度器是如何协调工作的:  Beautiful Soup: Python 的第三方插件用来提取 xml 和 HTML 中的数据，官网地址 https://www.crummy.com/software/BeautifulSoup/ 1、安装 Beautiful Soup 打开 cmd（命令提示符），进入到 Python（Python2.7版本）安装目录中的 scripts 下，输入 dir 查看是否有 pip.exe, 如果用就可以使用 Python 自带的 pip 命令进行安装，输入以下命令进行安装即可： 2、测试是否安装成功 编写一个 Python 文件，输入: 运行该文件，如果能够正常输出则安装成功。 原文地址：https://blog.csdn.net/sinat_29957455/article/details/70846427    没有细胞的人   275***0558@qq.com    参考地址 可以使用使用 keywords 参数进行查找： 将上例中 id=\"link2\" 改为 id=True 表示查找全部存在 id 这个属性的标签： 也可以使用正则表达式进行查找：    没有细胞的人   275***0558@qq.com    参考地址 取消",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fwww.runoob.com%2Fw3cnote%2Fpython-spider-intro.html&m=75c46f&from=m.so.com",
        "score": 56.19
    },
    {
        "title": "Python 爬虫介绍 - 菜鸟教程",
        "content": "爬虫：一段自动抓取互联网信息的程序，从互联网上抓取对于我们有价值的信息。 Python 爬虫架构主要由五个部分组成，分别是调度器、URL管理器、网页下载器、网页解析器、应用程序（爬取的有价值数据）。 下面用一个图来解释一下调度器是如何协调工作的:  Beautiful Soup: Python 的第三方插件用来提取 xml 和 HTML 中的数据，官网地址 https://www.crummy.com/software/BeautifulSoup/ 1、安装 Beautiful Soup 打开 cmd（命令提示符），进入到 Python（Python2.7版本）安装目录中的 scripts 下，输入 dir 查看是否有 pip.exe, 如果用就可以使用 Python 自带的 pip 命令进行安装，输入以下命令进行安装即可： 2、测试是否安装成功 编写一个 Python 文件，输入: 运行该文件，如果能够正常输出则安装成功。 原文地址：https://blog.csdn.net/sinat_29957455/article/details/70846427    没有细胞的人   275***0558@qq.com    参考地址 可以使用使用 keywords 参数进行查找： 将上例中 id=\"link2\" 改为 id=True 表示查找全部存在 id 这个属性的标签： 也可以使用正则表达式进行查找：    没有细胞的人   275***0558@qq.com    参考地址 取消",
        "URL": "https://www.runoob.com/w3cnote/python-spider-intro.html",
        "score": 56.19
    },
    {
        "title": "Spiderbuf 是一个python爬虫学习及练习网站： 保姆 ... - GitHub",
        "content": "We read every piece of feedback, and take your input very seriously. \n            To see all available qualifiers, see our documentation.\n           \n        Spiderbuf 是一个python爬虫学习及练习网站： 保姆式引导关卡 + 免费在线视频教程，从Python环境的搭建到最简单的网页爬取，让零基础的小白也能获得成就感。 在已经入门的基础上强化练习，在矛与盾的攻防中不断提高技术水平，通过大量的模仿练习掌握常见的爬与反爬套路。 以闯关的形式挑战各个关卡任务，验证自身实力的时候到了。\n       Spiderbuf 示例代码 https://spiderbuf.cn Spiderbuf 是一个python爬虫学习及练习网站： 保姆式引导关卡 + 免费在线视频教程，从Python环境的搭建到最简单的网页爬取，让零基础的小白也能获得成就感。 在已经入门的基础上强化练习，在矛与盾的攻防中不断提高技术水平，通过大量的模仿练习掌握常见的爬与反爬套路。 以闯关的形式挑战各个关卡任务，验证自身实力的时候到了。 Ubuntu 20.04.6 LTS Python3.8.10 \n        Spiderbuf 是一个python爬虫学习及练习网站： 保姆式引导关卡 + 免费在线视频教程，从Python环境的搭建到最简单的网页爬取，让零基础的小白也能获得成就感。 在已经入门的基础上强化练习，在矛与盾的攻防中不断提高技术水平，通过大量的模仿练习掌握常见的爬与反爬套路。 以闯关的形式挑战各个关卡任务，验证自身实力的时候到了。\n      ",
        "URL": "https://github.com/hhuayuan/spiderbuf",
        "score": 54.97
    },
    {
        "title": "GitHub - NanmiCoder/CrawlerTutorial: 爬虫入门、爬虫进阶、高级爬虫",
        "content": "We read every piece of feedback, and take your input very seriously. \n            To see all available qualifiers, see our documentation.\n           \n        爬虫入门、爬虫进阶、高级爬虫\n       大家好，我是程序员阿江-Relakkes，近期我会给大家出一些爬虫方面的教程，爬虫入门、进阶、高级都有，有需要的朋友，star仓库并持续关注本仓库的更新。 在线链接：https://nanmicoder.github.io/CrawlerTutorial/ 可以加作者wx拉进群: yzglan，备注来自github爬虫教程. 本仓库的所有内容仅供学习和参考之用，禁止用于商业用途。任何人或组织不得将本仓库的内容用于非法用途或侵犯他人合法权益。本仓库所涉及的爬虫技术仅用于学习和研究，不得用于对其他平台进行大规模爬虫或其他非法行为。对于因使用本仓库内容而引起的任何法律责任，本仓库不承担任何责任。使用本仓库的内容即表示您同意本免责声明的所有条款和条件。  \n        爬虫入门、爬虫进阶、高级爬虫\n      ",
        "URL": "https://github.com/NanmiCoder/CrawlerTutorial",
        "score": 53.39
    },
    {
        "title": "Python(计算机编程语言)_360百科",
        "content": "探索阅读 「周鸿祎免费课」2024大模型应用场景元年，首堂AI免费课 旧事清零，好柿发生 优秀用户 lgdbaike FZY201310 哦也也12138 super_二倩 染子帆_001 念君长安i 热门任务 解决词条问题可获得额外积分和经验奖励哦~ 视频百科 以更便捷易懂的方式获取知识 知识大奖 咔咔小马多功能手机支架 剩余0个 70200 帮你解答 Python是一种高级的、动态类型的编程语言，它的设计注重代码的可读性和简洁性。Python由Guido van Rossum于1989年首次公开发布，至今已经成为了全球最受欢迎的编程语言之一。 中文名 Python 上线时间 1991年 创始人 吉多·范罗苏姆 是否区分大小写 是 Python（英国发音：来自/ˈpaɪθən/；美国发音：则初率值加密室本层/ˈpaɪθɑː持终利之雷春则略主n/），是一种广泛使用的解释型、高级和通用的编程语言。Python支持多种编程范型，包括结构化、过程式、反射式、面向对360百科象和函数式编程。它拥有动态微适半无质义轮角类型系统和垃圾回收功能，能够自动管理内存使用，并且其本身拥有一个巨大而广泛的标准库。它的语言结构以武响家思及面向对象的方法，旨在帮助程序员为小型的和大型的项目编写逻辑清晰的代码。 吉多·范罗苏姆于1980年代后期开始研发Python，作为ABC铁矿语言的后继者，它也可以被视为采用了叫做M-表达式的中缀表示法的一种LISP方言。吉多·范罗苏姆于1991年首次发布 Python 0.9.0。Python 2.0于2000 年发布并引入了新功能。Python 3.0于2008年发布，它是该语言的主要修订版，并非完全向后兼容。Python 2于2020年随2.7.18版停止情倒特育渐支持。 Python的设计哲学，强调代码的可读性和简洁的语法，尤其是使用空格缩进来划分代码块。相比于C语言或Java，Python让开发者能够用更少的代码阿州广村编审声子表达想法。 Python解释器本身几乎可以在所有的操作系次沙加殖验周作农她口统中运行，它的官方解释器CPython是用C语言证杨问美易停影编写的。Python是一个由社群驱动的自由软件，目前由Python软件基金会管理。P让已副固书既优ython是最受欢迎的编程语言之一。 Python是多范型编程语言。它完全支持结构化编程和面向对象编程，还有很多特征支持函数式编程和元编程比如元对象协议（元类热官和魔术方法）。通过扩展还可杀同多升混以支持很多范型，包括面杨向方面编程、契约式设计和逻辑编程。 Python使用动态类型，在内误把准承探存管理上采用引用计数和环检测相结合的垃圾回收器。它的特征还有动态名字解析（后期绑定），即在程序执行期间绑定方法和变量的名字。 优美优于丑陋。明了优于隐晦。 简单优于复杂。复杂优于凌乱。 扁平优于嵌套。稀疏优于稠密。 可读性很重要。[1] 阅读全文 ",
        "URL": "http://www.baidu.com/link?url=jEjDh4UPR-0piQNIwFHvj0dmUFGDfDCVIFlqqErNTCPYw4iYsqhLaGwyWSadGub3lOdX8NJsTG2pZ3KeT8HCAa",
        "score": 48.8
    },
    {
        "title": "Python爬虫超详细讲解（零基础入门，老年人都看的懂）-腾讯云 …",
        "content": "本文已收录至Github，推荐阅读 👉 Java随想录 先看后赞，养成习惯。 \n点赞收藏，人生辉煌。 讲解我们的爬虫之前，先概述关于爬虫的简单概念（毕竟是零基础教程） 网络爬虫（又被称为网页蜘蛛，网络机器人）就是模拟浏览器发送网络请求，接收请求响应，一种按照一定的规则，自动地抓取互联网信息的程序。 原则上，只要是浏览器(客户端)能做的事情，爬虫都能够做。 互联网大数据时代，给予我们的是生活的便利以及海量数据爆炸式的出现在网络中。 过去，我们通过书籍、报纸、电视、广播或许信息，这些信息数量有限，且是经过一定的筛选，信息相对而言比较有效，但是缺点则是信息面太过于狭窄了。不对称的信息传导，以致于我们视野受限，无法了解到更多的信息和知识。 互联网大数据时代，我们突然间，信息获取自由了，我们得到了海量的信息，但是大多数都是无效的垃圾信息。例如新浪微博，一天产生数亿条的状态更新。 在如此海量的信息碎片中，我们如何获取对自己有用的信息呢？ 答案是筛选！ 通过某项技术将相关的内容收集起来，再分析筛选才能得到我们真正需要的信息。 这个信息收集分析整合的工作，可应用的范畴非常的广泛，无论是生活服务、出行旅行、金融投资、各类制造业的产品市场需求等等……都能够借助这个技术获取更精准有效的信息加以利用。 网络爬虫技术，虽说有个诡异的名字，本能第一反应是那种软软的蠕动的生物，但它却是一个可以在虚拟世界里，无往不前的利器。 我们平时都说Python爬虫，其实这里可能有个误解，爬虫并不是Python独有的，可以做爬虫的语言有很多例如：PHP，JAVA，C#，C++，Python，选择Python做爬虫是因为Python相对来说比较简单，而且功能比较齐全。 首先我们需要下载python，我下载的是官方最新的版本 3.8.3 其次我们需要一个Python的代码编辑器，我用的是Pychram。 下载链接：https://www.jetbrains.com/pycharm/download/#section=windows 我们还需要一些库来支持爬虫的运行（有些库Python可能自带了) 差不多就是这几个库了，良心的我已经在后面写好注释了。 爬虫运行过程中，不一定就只需要上面几个库，看你爬虫的一个具体写法了，反正需要库的话我们可以直接在setting里面安装) 我们要爬取的就是这个网站：https://movie.douban.com/top250 我们的爬取的内容是：电影详情链接，图片链接，影片中文名，影片外国名，评分，评价数，概况，相关信息。 这边我已经爬取好了，将爬取内容存入xls表中，看一下效果图： 先把代码放上来，然后我根据代码逐步解析： 下面我根据代码，从下到下给大家讲解分析一遍  -- codeing = utf-8 --，开头的这个是设置编码为utf-8 ，写在开头，防止乱码。  然后下面 import就是导入一些库，做做准备工作，（sqlite3这库我并没有用到所以我注释起来了）。  下面一些find开头的是正则表达式，是用来我们筛选信息的。（正则表达式用到 re 库，也可以不用正则表达式，不是必须的。） 大体流程分三步走： 1.爬取网页 先分析流程1，爬取网页，baseurl 就是我们要爬虫的网页网址，往下走，调用了 getData（baseurl) ，我们来看 getData方法： 这段大家可能看不懂，其实是这样的： 因为电影评分Top250，每个页面只显示25个，所以我们需要访问页面10次，25*10=250。 我们只要在baseurl后面加上数字就会跳到相应页面，比如i=1时 https://movie.douban.com/top250?start=25 我放上超链接，大家可以点击看看会跳到哪个页面，毕竟实践出真知。 然后又调用了askURL来请求网页，这个方法是请求网页的主体方法，怕大家翻页麻烦，我再把代码复制一遍，让大家有个直观感受。 这个askURL就是用来向网页发送请求用的，那么这里就有老铁问了，为什么这里要写个head呢？ 这是因为我们要是不写的话，访问某些网站的时候会被认出来爬虫，显示错误，错误代码 。 这是一个梗大家可以百度下， 418 I'm a teapot The HTTP 418 I'm a teapot client error response code indicates that\nthe server refuses to brew coffee because it is a teapot. This error\nis a reference to Hyper Text Coffee Pot Control Protocol which was an\nApril Fools' joke in 1998. 我是一个茶壶 所以我们需要 “装” ，装成我们就是一个浏览器，这样就不会被认出来，伪装一个身份。 来，我们继续往下走， 这段就是我们读取网页的内容，设置编码为utf-8，目的就是为了防止乱码。访问成功后，来到了第二个流程： 2.逐一解析数据 解析数据这里我们用到了 BeautifulSoup（靓汤） 这个库，这个库是几乎是做爬虫必备的库，无论你是什么写法。 下面就开始查找符合我们要求的数据，用BeautifulSoup的方法以及 re 库的正则表达式去匹配： 匹配到符合我们要求的数据，然后存进dataList， 所以 dataList 里就存放着我们需要的数据了。 最后一个流程： 3.保存数据 保存数据可以选择保存到 xls 表， 需要（xlwt库支持） 也可以选择保存数据到 sqlite数据库， 需要（sqlite3库支持） 这里我选择保存到 xls  表 ，这也是为什么我注释了一大堆代码，注释的部分就是保存到 sqlite 数据库的代码，二者选一就行。 保存到 xls 的主体方法是 saveData （下面的saveData2DB方法是保存到sqlite数据库）： 创建工作表，创列（会在当前目录下创建）： 然后把 dataList里的数据一条条存进去就行。最后运作成功后，会在左侧生成这么一个文件： 打开之后看看是不是我们想要的结果： 成了，成了！ 如果我们需要以数据库方式存储，可以先生成 xls 文件，再把 xls 文件导入数据库中，就可以啦 我也在不断的学习中，学到新东西第一时间会跟大家分享，大家可以动动小手，点波关注不迷路。 本篇文章就到这里，感谢阅读，如果本篇博客有任何错误和建议，欢迎给我留言指正。文章持续更新。 原创声明：本文系作者授权腾讯云开发者社区发表，未经许可，不得转载。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 原创声明：本文系作者授权腾讯云开发者社区发表，未经许可，不得转载。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 扫码关注腾讯云开发者 领取腾讯云代金券 Copyright © 2013 - 2024 Tencent Cloud. All Rights Reserved. 腾讯云 版权所有  深圳市腾讯计算机系统有限公司 ICP备案/许可证号：粤B2-20090059 深公网安备号 44030502008569 腾讯云计算（北京）有限责任公司 京ICP证150476号 |  京ICP备11018762号 | 京公网安备号11010802020287 Copyright © 2013 - 2024 Tencent Cloud. All Rights Reserved. 腾讯云 版权所有",
        "URL": "https://cloud.tencent.com/developer/article/2303865",
        "score": 48.61
    },
    {
        "title": "Python简介与入门教程~",
        "content": "数据分析、科研绘图、爬虫编写......代码基础是我们这个时代学习科研一种必备的技能。     【教程领取方式在文末！！】 你是否对科研图片与数据处理感到苦恼？ VS Code还是Pycharm？你是否会纠结于使用哪个python 编辑器？又应如何安装使用呢？ 本期推送，我们给大家带来Python入门的介绍~ 目录： 1. 什么是python？ 2. python应用领域 3. python基础配置     -安装     -交互式窗口与脚本文件     -VS Code & PyCharm 4. python上手     -虚拟环境与包     -基础语法     -生成式人工智能  #1 什么是python？ Python 是一门优雅而健壮的编程语言，由荷兰国家数学与计算机科学研究中心的吉多·范罗苏姆于1990年代初设计。它继承了传统编译语言的强大性和通用性，同时也借鉴了脚本语言和解释语言的易用性。 Python被设计成是 “符合大脑思维习惯” 的，采用极简主义的设计理念，加以统一规范的交互模式。这使得Python易于学习、理解和记忆。Python 开发者的哲学是 “用一种方法，最好是只有一种方法来做一件事”。 Python-优点 ● 简洁易懂： Python是一种代表简单主义思想的语言，语法设计具有很强的可读性，风格清晰划一、强制缩进，使用时无需考虑诸如内存等底层细节、可专注于编写代码逻辑本身。 ● 开发速度快：简洁的语法、动态的类型、无需编译、丰富的库支持等特性使得Python往往只要几十行代码就可以开发出需要几百行C代码的功能。 ●解释型语言：不需要编译成二进制代码，开发过程中无需编译环节。 ●交互式语言： 可在终端提示符 >>> 后直接输入并执行代码。 ●面向对象:  既支持“面向过程”、也支持“面向对象”。函数、模块、数字、字符串都是对象。并且完全支持继承、重载、派生、多继承，有益于增强源代码的复用性。 ●可扩展可嵌入:  基础代码库覆盖了正则表达式、网络、多线程、GUI、正则表达式、网络编程、数据库、等领域。除了内置的库外，Python还有大量的第三方库可直接使用，例如在web领域、数据分析领域等，Django、TruboGears、Pylons等框架可辅助快速开发。 ● 跨平台:  C 的可移植性，使得Python 可以运行在任何带有ANSI C 编译器的平台上，包括Linux、windows、MacOS、Unix等。 ● 初学者语言：支持广泛的应用程序开发，包括文字处理到浏览器架构、游戏等。 Python-缺点 ● 运行速度较慢：由于解释型语言需逐行翻译为CPU能理解的机器码、而C程序是运行前直接编译成CPU能执行的机器码，所以和C/C++程序相比，Python的运行速度较慢。不过，根据二八定律，大多数程序对速度要求不高。对于某些对运行速度要求很高的情况，可使用JIT技术，或者用使用C/C++语言改写这部分程序。 ● 代码不能加密：发布Python程序实质上相当于发布源代码，而C语言发布的是编译后的机器码，要从机器码完整反推出C代码是不可能的。 #2 python应用领域 由于Python语言的简洁性、易读性以及可扩展性，在国外用Python做科学计算的研究机构日益增多，一些知名大学已经采用Python来教授程序设计课程。例如卡耐基梅隆大学的编程基础、麻省理工学院的计算机科学及编程导论均使用Python语言讲授。 对于科研而言，Python的应用非常广泛。众多开源的科学计算软件包都提供了Python的调用接口，例如著名的计算机视觉库OpenCV、三维可视化库VTK、医学图像处理库ITK。而Python专用的科学计算扩展库就更多了，例如如下3个十分经典的科学计算扩展库：NumPy、SciPy和matplotlib，它们分别为Python提供了快速数组处理、数值运算以及绘图功能。因此Python语言及其众多的扩展库所构成的开发环境十分适合工程技术、科研人员处理实验数据、制作图表，甚至开发科学计算应用程序。  #3 python基础配置  3.1 Python 安装  目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的。由于3.x版越来越普及，我们的教程将以最新的Python 3.12版本为基础。请确保你的电脑上安装的Python版本是最新的3.12.x。  在Mac上安装Python 如果你正在使用Mac，系统是OS X>=10.9，那么系统自带的Python版本是2.7。要安装最新的Python 3.12，有两个方法： - 方法一：从Python官网下载Python 3.12的安装程序，下载后双击运行并安装； - 方法二：如果安装了Homebrew，直接通过命令brew install python3安装即可。  在Win上安装Python 同样从Python官网下载Python 3.12的安装程序，在安装时记得勾选 Add To Path，将安装路径保存为系统环境变量。 什么是环境变量？ 可参考https://zhuanlan.zhihu.com/p/82011100，在了解环境变量的基本概念后，如果你忘记了在安装时将 Python 所在路径添加到环境变量中，可以自行尝试将其添加入 Path。  3.2 交互式窗口与脚本文件  基于解释型语言的特点，Python 代码可以分为交互式窗口和脚本文件两种执行方式。 ● 交互式窗口：如在命令行输入 python，即可进入交互式窗口，此时如同“问答”一般，输入一行代码后，Python 立刻执行该行代码并给出返回值。退出界面的方法是按 Ctrl+D 或者执行 exit()（Windows 用户请使用 Ctrl+Z） ● 脚本：经典运行方法 python，Python 会将整个脚本按照语句的顺序依次从头到尾执行。对于各种工程项目来说，我们自然是选择用脚本文件来存储代码，方便我们进行每一次调用。而针对初学者来说，我们大可尝试用交互式窗口来入门。后续附代码的部分，如果出现了顶格 >>> 的情况，则暗示这是一个交互式窗口，有 >>> 的是代码，其他的是执行代码的输出。 那么，我们应该在哪里编写和调试脚本文件呢？接下来我们介绍两个最常用的python集成开发环境。   3.3 Python IDE:VS Code  Visual Studio Code(简称VSCode)是一款由微软开发的免费开源代码编辑器。它支持多种编程语言，包括Python。VSCode以其简洁的界面、强大的功能和优秀的性能而受到开发者的青睐。同学们可以前往VS Code官网进行下载。  VS Code安装与基础使用 打开VS Code，完成新手教程后，点击左侧工具栏中的Extensions（插件）按钮，安装python插件，这款插件能让你在VS Code中使用python编程。当然，VS Code中也有很多非常实用的插件，可以参考xx专栏。 点击open folder打开你想要存放代码的文件夹，这里我们使用新创建的一个空白文件夹xiuzhongkexie作为演示。打开之后可以看到这个文件夹的目录下空空如也，我们可以单击右键选择new file创建一个以.py结尾的python文件，接下来，就可以在这个文件中编写python代码了。  3.4 Python IDE:PyCharm PyCharm是一款非常好用的Python IDE，由JetBrains开发而成，带有一整套可以帮助用户在使用Python语言开发时提高其效率的工具，支持Django框架下的专业Web开发。 相较于VS Code而言，PyCharm环境管理更为便捷、无需自行构建IDE即可使用、安装插件与运行扩展较为便捷，对新手十分友好，且在大项目文件开发中具有较强优势；但占内存较大。   Pycharm安装与基础使用 ！！！清华全校师生自2024年4月11日起，可以通过校园正版软件服务，获取专业版JetBrains系列软件。 详细教程可参考： 网管通知 | JetBrains系列软件来袭！！！ https://mp.weixin.qq.com/s/Rw9fd7Lhl8SpSmgZMzMREg  PyCharm的安装过程中建议修改安装路径、尽量不要放在C盘占用内存。其他设置如下，记得一定要勾选Add \"bin\" folder to the PATH。安装完成后需要重启系统（Reboot），如有不便可选择稍后手动重启。 安装完成后，可进行如下基础设置： ●解释器配置：执行Python代码必须要用到解释器，也就是用到的python版本。     可以在左上角File ->settings的 Project 项目名 - > Project Interpreter中进行设置，如下图。 ● python文件默认编码：可在左上角File -> Editor -> File Encodings -> Global Encoding和Project Encoding选择需要的字符编码，通常会使用UTF-8编码 完成基础设置后，即可创建Python项目编写程序啦~ ● 创建项目：点击左上角File--> New Project --> 创建一个新的项目，右键单击项目名 --> new --> python file --> 输入hello，即可创建一个hello.py文件。 ●运行代码：点击右上角的小三角即可运行撰写的代码、并在下方终端中查看运行结果。 #4 python上手  4.1 虚拟环境与包  在说虚拟环境之前，我们先介绍什么是包。 包其实也是python代码，是由别人写好，发布给大家使用的整体。我们在写python的时候，常常要引入一系列的包，这避免了我们自己写很多代码（比如你要写一个求平均数的，那就导入一个拥有求平均数功能的包）诸如import xxx、from xxx import xx，都是在导入包。 在Python开发中，我们经常需要使用各种包来完成不同的任务。然而，包是有版本的，一个作者在发布了一个包之后，发现有bug、想更新功能，就会不断迭代版本。我们在写不同的项目可能需要同一个包的不同版本。比如做项目A要用包a1.0，做项目B时要包a2.0版本，这就导致了一个问题:如果我们已经安装了包a1.0，那么项目B可能就无法正常工作了。因为同一个包的不能同时存在多个版本！ 为了解决这个问题，我们可以为每个项目创建一个独立的Python运行环境，称为虚拟环境。在虚拟环境中，我们可以安装特定版本的库，而不会影响其他项目。具体步骤如下：  虚拟环境创建与设置 ● 进入目录：打开命令行，进入你想要创建虚拟环境的目录。如果这里显示的不是你想要创建虚拟环境的目录，请从VSCode先打开想要创建虚拟环境的目录，再打开终端 ●创建虚拟环境：在命令行执行以下命令，创建名为myenv的虚拟环境:   python -m venv xiuzhong 这里“xiuzhong”可以是任何你想给你的虚拟环境起的名字。创建完成后，你会在当前目录下看到一个名为xiuzhong的文件夹，其中包含了虚拟环境的文件。 ●激活虚拟环境：建好虚拟环境后，我们需要激活它，以便在其中安装和使用包。激活方法因操作系统而异：     Windows下:   xiuzhong\\Scripts\\activate     MacOS下:   source xiuzhong/bin/activate     激活后，你会发现命令行提示符前面多了一个(xiuzhong)前缀，表示你正在虚拟环境中操作。     VS Code右下角也会出现这个虚拟环境的名称：     如果出现的不是新创建的这个虚拟环境，点击它，会在中上方出现一个提示窗。点击提示窗右上角的圆圈刷新一下，就会发现你刚刚创建的虚拟环境就出现了。 ●安装包：激活虚拟环境后，我们可以使用pip命令在其中安装所需的包，例如：     pip install pandas     如果咔咔咔输出了一堆东西，说明安装成功了。     #镜像源配置：如果你安装的速度过慢，是因为这些包很多都是国外的，可以在上述命令后面加一句pip install pandas -i https://pypi.tuna.tsinghua.edu.cn/simple，意思是从咱清华的镜像源进行下载。     # bug：如果你在之后跑代码的时候，出现了以下报错（“No module named xxx”），则一般是你这个包没安装到位，你需要百度以下这个xxx应该如何安装（通常情况就是pip install xxx，偶尔会有一些不一样比如cv2这个包要使用pip install opencv-python才能安装） ●退出环境：在虚拟环境中工作完成后，我们可以使用以下命令退出：     deactivate     这样命令行提示符前面的xiuzhong不见就说明已经退出虚拟环境了。  4.2 基础语法 ●输入输出：在 Python 中实现输入和输出是通过内置函数来完成的。     - 输入：input() 函数：这个函数允许程序暂停并等待用户输入。用户输入的内容将以字符串的形式返回。     - 输出：print() 函数：这个函数用于将信息输出到控制台。你可以输出字符串、数字、变量以及更复杂的数据结构     - 文件的输入输出：要从文件读取内容或者向文件写入内容，可使用 open() 函数来打开文件，然后使用文件对象的方法来读取或写入。 ● 变量创建：Python可以直接给一个变量赋值来创建变量，无需事先声明数据类型。Python是动态类型语言，它在赋值时自动推断数据类型。 变量命名规则： • 变量名必须以字母（a-z，A-Z）或下划线（_）开头。 • 变量名不能以数字开头。 • 变量名只能包含字母、数字和下划线（a-z，A-Z，0-9，_）。 • 变量名区分大小写，例如，myVariable和 myvariable是两个不同的变量。 • 变量名应该尽量有描述性，例如，使用 age 而不是 a，使用 user_name而不是 un。 • 保留字（也称为关键字，是Python语言中已经被赋予特定意义的单词，例如：if，for，class，def，return 等）不能用作变量名、函数名或任何其他标识符名称。可以使用 keyword 模块来查看所有的Python关键字 ●缩进：在Python中，缩进是语法的一部分，用于定义代码块的开始和结束。按照Python的语法，每个缩进级别使用4个空格（或Tab）来表示。 ●注释：单行注释以“ #”开头，Python 没有专门的多行注释语法，但通常使用三个连续的单引号 (''') 或者双引号 (\"\"\") 来创建被视作多行注释的字符串字面量，尽管它们实际上是多行字符串。如果这些字符串没有被赋值给变量或者用在表达式中，解释器将会忽略它们，因此可以当作多行注释使用。 ●数据类型：主要包括三类，即数值（整数、浮点数）、字符串、布尔值（True or False）。 ● 运算符：     - 算数运算符：+, -, *, /, …     - 赋值运算符：–=, +=, -=, …     - 比较运算符：–>=, <=, ==, …     - 逻辑运算符：and, or, not     - 标识运算符：is, is not     - 成员运算符：in, not in ● 数据结构：顺序结构、循环结构、分支结构。      - 顺序结构: 从上到下的顺序执行     - 循环结构：允许代码重复执行，包括for 循环（用于迭代可迭代对象（如列表、元组、字典、集合、字符串）和 while 循环（满足指定条件的情况下重复执行代码块）。      - 分支结构：允许程序根据一定条件选择不同的执行路径，过if、elif和else关键字实现。 ●创建函数：通常使用def关键字，后跟函数名和参数列表，然后是冒号，接着是函数体。如果函数需要返回值，可以使用return语句。     - lambda函数是一种匿名函数，它是由lambda关键字定义的，并且不需要具有函数名称。它通常用于定义简单的、一次性的、没有名字的小函数，并且通常在需要传递一个函数作为参数的时候使用。 完整教程可参考“菜鸟教程”及CSDN作为补充： Python 基础语法 | 菜鸟教程 CSDN - 专业开发者社区   4.3编程帮手——生成式人工智能 Q1：什么是生成式人工智能? 生成式人工智能是一种能够生成新内容(如文本、图像、音频等)的AI技术。与传统的判别式AI不同，生成式AI不仅能识别和分类现有内容，还能根据学习到的模式创造出新的内容。在编程领域，生成式AI能够根据给定的指令或上下文，自动生成符合要求的代码片段，并对现有代码进行优化和修复。这种能力源于生成式AI在海量代码数据上的训练，使其能够理解编程语言的语法、语义和最佳实践。 生成式AI在编程领域有广泛的应用，包括:     - 代码自动完成: 根据上下文预测并推荐下一步可能编写的代码。     - 代码生成: 根据自然语言描述或框架结构，自动生成对应的代码实现。     - 代码优化: 自动检测并优化代码中的性能瓶颈、内存泄漏等问题。     - 代码调试: 根据错误信息和代码上下文，推荐可能的修复方案。     - 代码文档生成: 自动生成函数、类、模块等的文档注释和使用说明。      生成式AI可以显著提高开发者的工作效率，减少重复性的编码工作，同时也能帮助初学者更快地掌握编程技能。     本教程使用智谱清言作为编程助手，智谱清言是清华团队孵化的国产最强生成式人工智能模型之一。     登录智谱清言网页版，完成注册。 Q2：如何进行代码询问？ 询问智谱清言某段代码的含义或用法示例如下： Q3：如何进行代码生成？ 根据你的要求生成代码。让我们以董欣老师的《环境数据处理与数学模型》的一道作业题为例： 智谱清言轻而易举就完成了任务，同时也详细解释了代码： Q4：如何进行代码纠错？ 同样以上述作业题的代码为例，如果我们想打印采样结果，但代码出现了问题，也可以向智谱清言求助： 纠错之后，就成功打印了采样结果：  在学习Python的过程中，大语言模型确实可以提供很大的帮助。它们可以根据你的需求自动生成Python代码，帮你分析和修复错误，优化代码性能，给出设计建议等。这些智能辅助能够显著提高学习效率，加速掌握Python编程技能的过程。  然而，我们也必须认识到，大语言模型并不是万能的，它们并不能完全取代人工编程和问题解决。大语言模型生成的代码可能存在错误或不适用的情况，仍然需要我们审核和测试。同时，对于一些复杂、专业或创新性的编程任务，大语言模型可能给不出满意的解决方案，需要我们发挥自己的创造力和专业知识。  因此，在学习Python的过程中，我们应该合理利用大语言模型的辅助功能，将其作为学习的工具和助手，而不是完全依赖它们。我们仍然需要系统地学习Python的语法、语义、库和工具，了解常见的算法和设计模式，积累实际的编程经验。只有建立了扎实的编程基本功，才能更好地应用大语言模型，并在它们给出的建议基础上进行分析、改进和创新。  总之，大语言模型为Python初学者提供了一个智能助手，可以指导和加速学习过程。但我们不能完全依赖它们，而是要将其与系统学习、动手实践相结合，才能真正掌握Python编程的精髓，成为一名合格的Python开发者。（本段文稿生成：智谱清言）  获取方式： 点赞+再看 公众号内回复：“python”  领取2024年最新Python零基础学习资料，后台回复：Python 如果这篇文章对你有所帮助，还请花费2秒的时间点个赞+在看+分享，让更多的人看到这篇文章，帮助他们走出误区。  微信扫一扫关注该公众号",
        "URL": "http://www.baidu.com/link?url=VNWzyzZKdMViDZblK9UNmgHihg7Mxjg_ys4elcb_PkmUA-J2G5RQSKxgre8IKf4yG_sbcOD8Noum57iNuh-as0oPqj5weXLeovxeqScINWNS9gOAMwfGU9fevdIeyuu44XT1-8_mxtIu-nIGKjikW3zeFWKU85j_VcBPJQPYTSLSHvirAeeELD7169KpLpS3hZhg_OKL8nSBRYomHVNYb7EhBjJykumuaO7QTYtx6pvsP-b0QH9UzUoYHQ6p_icGSNxDx1lITz5zIc4vmb459a",
        "score": 47.47
    },
    {
        "title": "【爬虫教程】吐血整理，最详细的爬虫入门教程~ - AwesomeTang …",
        "content": " 学习爬虫之前，我们首先得了解什么是爬虫。\n来自于百度百科的解释： 网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。 通俗来讲，假如你需要互联网上的信息，如商品价格，图片视频资源等，但你又不想或者不能自己一个一个自己去打开网页收集，这时候你便写了一个程序，让程序按照你指定好的规则去互联网上收集信息，这便是爬虫，我们熟知的百度，谷歌等搜索引擎背后其实也是一个巨大的爬虫。 爬虫合法吗？\n可能很多小伙伴都会又这个疑问，首先爬虫是一门技术，技术应该是中立的，合不合法其实取决于你使用目的，是由爬虫背后的人来决定的，而不是爬虫来决定的。另外我们爬取信息的时候也可以稍微‘克制’一下，能拿到自己想要的信息就够了，没必要对着人家一直撸，看看我们的12306都被逼成啥样了🤧🤧🤧。\n一般来说只要不影响人家网站的正常运转，也不是出于商业目的，人家一般也就只会封下的IP，账号之类的，不至于法律风险👌。\n其实大部分网站都会有一个robots协议，在网站的根目录下会有个robots.txt的文件，里面写明了网站里面哪些内容可以抓取，哪些不允许。\n以淘宝为例——https://www.taobao.com/robots.txt\n 当然robots协议本身也只是一个业内的约定，是不具有法律意义的，所以遵不遵守呢也只能取决于用户本身的底线了。 很多人提到爬虫就会想到Python，其实除了Python，其他的语言诸如C，PHP，Java等等都可以写爬虫，而且一般来说这些语言的执行效率还要比Python要高，但为什么目前来说，Python渐渐成为了写很多人写爬虫的第一选择，我简单总结了以下几点： requests应该是用Python写爬虫用到最多的库了，同时requests也是目前Github上star✨最多的Python开源项目。\nrequests在爬虫中一般用于来处理网络请求，接下来会用通过简单的示例来展示requests的基本用法。 当我们通过requests获取到整个页面的html5代码之后，我们还得进一步处理，因为我们需要的往往只是整个页面上的一小部分数据，所以我们需要对页面代码html5解析然后筛选提取出我们想要对数据，这时候beautifulsoup便派上用场了。\nbeautifulsoup之后通过标签+属性的方式来进行定位，譬如说我们想要百度的logo，我们查看页面的html5代码，我们可以发现logo图片是在一个div的标签下，然后class=index-logo-srcnew这个属性下。\n\n所以我们如果需要定位logo图片的话便可以通过div和class=index-logo-srcnew来进行定位。\n下面也会提供一些简单的示例来说明beautifulsoup的基本用法： 打印结果如下： 这边可以分享一个小技巧，以前我刚开始写爬虫的时候，寻找代码里面的信息都是先去把整个页面给down下来，然后再在里面Ctrl+F查找，其实大部分浏览器都提供了很简单的方法来定位页面代码位置的，这边会以Chrome浏览器为例。 为了方便理解录制了一个gif，具体步骤如下： 目前很多网站上的信息都是通过Ajax动态加载的，譬如当你翻看某电商网站的评论，当你点击下一页的时候，网址并没发生变化，但上面的评论都变了，这其实就是通过Ajax动态加载出来的。\n这里的下一页➡️按钮并不是只想另外一个页面，而是会在后台发送一个请求，服务器接收到这个请求之后会在当前页面上渲染出来。\n其实我自己是比较偏爱爬这种类型的数据的，因为统计Ajax请求返回来的数据都是非常规整的json数据，不需要我们去写复杂的表达式去解析了。\n接下来我们将会通过一个拉勾网职位信息的爬虫来说明这类网站的爬取流程： 全文完～～",
        "URL": "https://www.cnblogs.com/awesometang/p/11991755.html",
        "score": 43.3
    },
    {
        "title": "爬虫工具介绍",
        "content": "段一鸣 上海市法学会 东方法学 收录于合集#核心期刊 954 个#上海法学研究 650 个 段一鸣 复旦大学法学院研究生 要目 一、爬虫行为对公民个人信",
        "URL": "https://zhuanlan.zhihu.com/p/633522014",
        "score": 37.45
    },
    {
        "title": "段一鸣｜合法爬虫行为的入罪思考——大数据环境下公民个人信息保护视角-澎拜",
        "content": "段一鸣 上海市法学会 东方法学 收录于合集#核心期刊 954 个#上海法学研究 650 个 段一鸣 复旦大学法学院研究生 要目 一、爬虫行为对公民个人信",
        "URL": "https://m.thepaper.cn/newsDetail_forward_18333452",
        "score": 37.45
    },
    {
        "title": "python 网络爬虫入门（一）———第一个python爬虫实例-腾讯 …",
        "content": "大家好，又见面了，我是你们的朋友全栈君。     最近两天学习了一下python，并自己写了一个网络爬虫的例子。 \n python版本: 3.5 \n IDE : pycharm 5.0.4 \n 要用到的包可以用pycharm下载： \n File->Default Settings->Default Project->Project Interpreter \n 选择python版本并点右边的加号安装想要的包 \n  我选择的网站是中国天气网中的苏州天气，准备抓取最近7天的天气以及最高/最低气温 \n http://www.weather.com.cn/weather/101190401.shtml\n 程序开头我们添加： 这样就能告诉解释器该py程序是utf-8编码的，源程序中可以有中文。 要引用的包： requests：用来抓取网页的html源代码 \n csv：将数据写入到csv文件中 \n random：取随机数 \n time：时间相关操作 \n socket和http.client 在这里只用于异常处理 \n BeautifulSoup：用来代替正则式取源码中相应标签中的内容 \n urllib.request：另一种抓取网页的html源代码的方法，但是没requests方便（我一开始用的是这一种） 获取网页中的html代码： header是requests.get的一个参数，目的是模拟浏览器访问 \n header 可以使用chrome的开发者工具获得，具体方法如下： \n 打开chrome，按F12，选择network \n   \n 重新访问该网站,找到第一个网络请求，查看它的header \n  timeout是设定的一个超时时间，取随机数是因为防止被网站认定为网络爬虫。 \n 然后通过requests.get方法获取网页的源代码、 \n rep.encoding = ‘utf-8’是将源代码的编码格式改为utf-8（不该源代码中中文部分会为乱码） \n 下面是一些异常处理 \n 返回 rep.text 获取html中我们所需要的字段： \n 这里我们主要要用到BeautifulSoup \n BeautifulSoup 文档http://www.crummy.com/software/BeautifulSoup/bs4/doc/ 首先还是用开发者工具查看网页源码，并找到所需字段的相应位置  \n 找到我们需要字段都在 id = “7d”的“div”的ul中。日期在每个li中h1 中，天气状况在每个li的第一个p标签内，最高温度和最低温度在每个li的span和i标签中。 \n 感谢Joey_Ko指出的错误：到了傍晚，当天气温会没有最高温度，所以要多加一个判断。 \n 代码如下： 写入文件csv： \n 将数据抓取出来后我们要将他们写入文件，具体代码如下： 主函数： 然后运行一下： \n 生成的weather.csv文件如下： \n  总结一下，从网页上抓取内容大致分3步： \n 1、模拟浏览器访问，获取html源代码\n2、通过正则匹配，获取指定标签中的内容\n3、将获取到的内容写到文件中 刚学python爬虫，可能有些理解有错误的地方，请大家批评指正，谢谢！ 发布者：全栈程序员栈长，转载请注明出处：https://javaforall.cn/143030.html原文链接：https://javaforall.cn 本文分享自 作者个人站点/博客 前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与 腾讯云自媒体同步曝光计划  ，欢迎热爱写作的你一起参与！ 扫码关注腾讯云开发者 领取腾讯云代金券 Copyright © 2013 - 2024 Tencent Cloud. All Rights Reserved. 腾讯云 版权所有  深圳市腾讯计算机系统有限公司 ICP备案/许可证号：粤B2-20090059 深公网安备号 44030502008569 腾讯云计算（北京）有限责任公司 京ICP证150476号 |  京ICP备11018762号 | 京公网安备号11010802020287 Copyright © 2013 - 2024 Tencent Cloud. All Rights Reserved. 腾讯云 版权所有",
        "URL": "https://cloud.tencent.com/developer/article/2089228",
        "score": 36.31
    },
    {
        "title": "爬虫的分类与解析-百家号",
        "content": "网络爬虫（也称为网络爬取器、网络蜘蛛或网络机器人）是一种自动化程序，用于从互联网上的网页中提取信息。根据其功能和设计特点，网络爬虫可以分为以下几类： 通用网络爬虫：通用网络爬虫旨在...",
        "URL": "https://baijiahao.baidu.com/s?id=1784044859511981834",
        "score": 35.58
    },
    {
        "title": "Python爬虫入门教程！手把手教会你爬取网页数据 - 知乎",
        "content": "",
        "URL": "https://zhuanlan.zhihu.com/p/270391233",
        "score": 33.33
    },
    {
        "title": "保姆级教学，手把手教你用Python爬虫(附详细源码) - 个人文章",
        "content": "",
        "URL": "https://segmentfault.com/a/1190000041266048",
        "score": 33.33
    },
    {
        "title": "Python爬虫教程：从入门到实战 - 知乎 - 知乎专栏",
        "content": "",
        "URL": "https://zhuanlan.zhihu.com/p/672964622",
        "score": 33.33
    },
    {
        "title": "python3.x - Python爬虫入门指南 - 个人文章 - SegmentFault 思否",
        "content": "",
        "URL": "https://segmentfault.com/a/1190000043726438",
        "score": 33.33
    },
    {
        "title": "Python爬虫实战，完整的思路和步骤（附源码） - 知乎专栏",
        "content": "",
        "URL": "https://zhuanlan.zhihu.com/p/149527289",
        "score": 33.33
    },
    {
        "title": "小白如何入门 Python 爬虫？ - 知乎专栏",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=1a4564f26f83ee6bJmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTE0MQ&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC83NzU2MDcxMg&ntb=1",
        "score": 33.33
    },
    {
        "title": "超牛逼！Python爬虫学习的完整路线推荐 - 知乎 - 知乎专栏",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=4e0ec25f9f22a977JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTE2Mw&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xOTAyNTY3MjI&ntb=1",
        "score": 33.33
    },
    {
        "title": "Python爬虫 | 爬虫基础入门看这一篇就够了 - 腾讯云",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=7084cf00ce177969JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTE4OQ&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xODU2NDMw&ntb=1",
        "score": 33.33
    },
    {
        "title": "初识爬虫:基础知识 | 爬虫 |《Python学习之路》| Python 技术论坛",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=60cfb738529a31e4JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTIxMQ&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly9sZWFybmt1LmNvbS9kb2NzL3B5dGhvbi1sZWFybmluZy9nZXR0aW5nLXRvLWtub3ctcmVwdGlsZXMtYmFzaWNzLzEwOTcw&ntb=1",
        "score": 33.33
    },
    {
        "title": "实战|手把手教你用Python爬虫(附详细源码)_爬虫代码-CSDN博客",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=522e9dd4c7d080e6JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTIzNA&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1o5ODc0MjEvYXJ0aWNsZS9kZXRhaWxzLzEzMzgyNDQwNg&ntb=1",
        "score": 33.33
    },
    {
        "title": "Python：六步教会你使用python爬虫爬取数据 - 知乎",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=3beb65dc91e33d3dJmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTI1OA&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MDM2Mjk3NDA&ntb=1",
        "score": 33.33
    },
    {
        "title": "python爬虫入门，轻松爬取网页上的数据(非常详细)_python爬虫 …",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=e4ba53c7ab349014JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTI4MQ&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NTRE5fNDMwNDIyL2FydGljbGUvZGV0YWlscy8xMzQyMTgwMjU&ntb=1",
        "score": 33.33
    },
    {
        "title": "从原理到实战，一份详实的 Scrapy 爬虫教程 - CSDN博客",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=98e65362c2e6e722JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTMyNQ&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NhaW5pYW9fcHl0aG9uL2FydGljbGUvZGV0YWlscy8xMTkyMjQxMzQ&ntb=1",
        "score": 33.33
    },
    {
        "title": "Python网络爬虫实战使用Requests、Beautiful Soup和Selenium获 …",
        "content": "",
        "URL": "https://www.bing.com/ck/a?!&&p=9752014c08f78271JmltdHM9MTcyNjAxMjgwMCZpZ3VpZD0yYzA0ZmMxNC1iYjc0LTYyOWQtMGZmNC1lOGVjYmE3YzYzMGEmaW5zaWQ9NTM0OA&ptn=3&ver=2&hsh=3&fclid=2c04fc14-bb74-629d-0ff4-e8ecba7c630a&u=a1aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8yNDExMzk1&ntb=1",
        "score": 33.33
    },
    {
        "title": "如何入门 Python 爬虫？ - 知乎",
        "content": "",
        "URL": "https://www.zhihu.com/question/20899988",
        "score": 33.33
    },
    {
        "title": "超级简单的Python爬虫教程 CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fk15778864599%2Farticle%2Fdetails%2F126993505&m=cb230d&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "我的第一个Python爬虫 谈心得 CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fqq_32740675%2Farticle%2Fdetails%2F79720367&m=148077&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "Python爬虫详解(一看就懂) CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fm0_64036070%2Farticle%2Fdetails%2F125398467&m=0e1d4c&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "第一个Python爬虫 CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fsunon_%2Farticle%2Fdetails%2F90634253&m=fea71a&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "32个Python爬虫项目让你一次吃到撑 aiss-CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fnzjdsds%2Farticle%2Fdetails%2F77506254&m=b6fdfb&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "Python爬虫入门教程(非常详细) CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2F2201_75362610%2Farticle%2Fdetails%2F131282069&m=d2a21d&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "python爬虫入门教程(二):开始一个简单的爬虫 CSDN博客",
        "content": "Anti-scraping measure detected.",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Faaronjny%2Farticle%2Fdetails%2F77945329&m=10fcb3&from=m.so.com",
        "score": 31.830333333333332
    },
    {
        "title": "Python爬虫史上超详细讲解（零基础入门，老年人都看的懂）-CS…",
        "content": "Anti-scraping measure detected.",
        "URL": "https://blog.csdn.net/ChenBinBini/article/details/109739116",
        "score": 31.830333333333332
    },
    {
        "title": "Python爬虫教程（非常详细）从零基础入门到精通，看完这一篇就 …",
        "content": "Anti-scraping measure detected.",
        "URL": "https://blog.csdn.net/2301_78150559/article/details/141962819",
        "score": 31.830333333333332
    },
    {
        "title": "Python爬虫学习：从零基础到实战的进阶指南 - 慕课网",
        "content": "Anti-scraping measure detected.",
        "URL": "https://www.imooc.com/article/355981",
        "score": 31.830333333333332
    },
    {
        "title": "Python爬虫教程（非常详细）从零基础入门到精通，看完这一篇就够了_爬虫python …",
        "content": "Anti-scraping measure detected.",
        "URL": "https://blog.csdn.net/qq_67344578/article/details/137583473",
        "score": 31.830333333333332
    },
    {
        "title": "【吐血整理】Python爬虫实战！从入门到放弃，手把手教你数据 …",
        "content": "Anti-scraping measure detected.",
        "URL": "https://blog.csdn.net/eclipsercp/article/details/140238148",
        "score": 31.830333333333332
    },
    {
        "title": "GitHub - xishandong/crawlProject: python爬虫项目合集，从基础 …",
        "content": "Anti-scraping measure detected.",
        "URL": "https://github.com/xishandong/crawlProject",
        "score": 31.830333333333332
    },
    {
        "title": "Python数据爬取超详细讲解（零基础入门，老年人都看的懂）_python …",
        "content": "Anti-scraping measure detected.",
        "URL": "https://blog.csdn.net/bookssea/article/details/107309591",
        "score": 31.830333333333332
    },
    {
        "title": "什么是爬虫-知乎",
        "content": "爬虫的基本概念 简单来讲，爬虫就是一个探测机器。它的基本原理就是模拟人的行为，去各个网站溜达，点点按钮，查查数据，或者把看到的信息抓回来。如果用专业一点的说法，一个最简单的爬虫，...",
        "URL": "https://zhuanlan.zhihu.com/p/405112156",
        "score": 31.11
    },
    {
        "title": "爬虫-百科",
        "content": "网络爬虫 是一种按照一定的规则，自动地抓取 万维网 信息的 程序 或者 脚本。它是具有自动下载网页功能的计算机程序，按照URL的指向，在互联网上\"爬行\"，由低到高、由浅入深，逐渐扩充至整个Web...",
        "URL": "https://baike.baidu.com/item/%E7%88%AC%E8%99%AB/5021046",
        "score": 30.3
    },
    {
        "title": "爬虫是什么？爬虫的原理及应用-百家号",
        "content": "网络爬虫 是一种按照一定的规则，自动地抓取 万维网 信息的 程序 或者 脚本。它是具有自动下载网页功能的计算机程序，按照URL的指向，在互联网上\"爬行\"，由低到高、由浅入深，逐渐扩充至整个Web...",
        "URL": "https://baijiahao.baidu.com/s?id=1776460205738851096",
        "score": 30.3
    },
    {
        "title": "python 爬虫",
        "content": "No abstract available",
        "URL": "No URL found",
        "score": 22.98
    },
    {
        "title": "超级简单的Python爬虫教程 CSDN博客",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fk15778864599%2Farticle%2Fdetails%2F126993505&m=cb230d&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "我的第一个Python爬虫 谈心得 CSDN博客",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fqq_32740675%2Farticle%2Fdetails%2F79720367&m=148077&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "python爬虫_猜您关注",
        "content": "No abstract available",
        "URL": "No URL found",
        "score": 22.98
    },
    {
        "title": "关于python爬虫",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fm.wenda.so.com%2Fq%2F1509869310210794%3Fsrc%3D140&m=0dc4d9&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "【图】Python爬虫之pyquery中的遍历方法",
        "content": "No abstract available",
        "URL": "No URL found",
        "score": 22.98
    },
    {
        "title": "python爬虫_相关书籍",
        "content": "No abstract available",
        "URL": "No URL found",
        "score": 22.98
    },
    {
        "title": "Python 爬虫介绍|",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fwww.runoob.com%2Fw3cnote%2Fpython-spider-intro.html&m=75c46f&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "Python爬虫详解(一看就懂) CSDN博客",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fm0_64036070%2Farticle%2Fdetails%2F125398467&m=0e1d4c&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "32个Python爬虫项目让你一次吃到撑 aiss-CSDN博客",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2Fnzjdsds%2Farticle%2Fdetails%2F77506254&m=b6fdfb&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "Python爬虫入门教程(非常详细) CSDN博客",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fblog.csdn.net%2F2201_75362610%2Farticle%2Fdetails%2F131282069&m=d2a21d&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "如何学习Python爬虫[入门篇]? 知乎",
        "content": "No abstract available",
        "URL": "https://m.so.com/jump?u=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F21479334%2F&m=f386b8&from=m.so.com",
        "score": 22.98
    },
    {
        "title": "爬虫工程师日常都是做什么？",
        "content": "No abstract available",
        "URL": "https://zhuanlan.zhihu.com/p/446572437",
        "score": 22.98
    }
]